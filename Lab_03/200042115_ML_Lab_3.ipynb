{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.1\n",
        "\n",
        "Load the dataset. Explore the dataset using pandas methods such as head(), info(), and describe()."
      ],
      "metadata": {
        "id": "hZiLzxRsGMHC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQXLeLPcFKSB",
        "outputId": "c809001e-a553-40a0-e100-4d7392394d1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       pelvic_incidence  pelvic_tilt numeric  lumbar_lordosis_angle  \\\n",
            "count        310.000000           310.000000             310.000000   \n",
            "mean          60.496653            17.542822              51.930930   \n",
            "std           17.236520            10.008330              18.554064   \n",
            "min           26.147921            -6.554948              14.000000   \n",
            "25%           46.430294            10.667069              37.000000   \n",
            "50%           58.691038            16.357689              49.562398   \n",
            "75%           72.877696            22.120395              63.000000   \n",
            "max          129.834041            49.431864             125.742385   \n",
            "\n",
            "       sacral_slope  pelvic_radius  degree_spondylolisthesis  \n",
            "count    310.000000     310.000000                310.000000  \n",
            "mean      42.953831     117.920655                 26.296694  \n",
            "std       13.423102      13.317377                 37.559027  \n",
            "min       13.366931      70.082575                -11.058179  \n",
            "25%       33.347122     110.709196                  1.603727  \n",
            "50%       42.404912     118.268178                 11.767934  \n",
            "75%       52.695888     125.467674                 41.287352  \n",
            "max      121.429566     163.071041                418.543082  \n",
            "\n",
            "   pelvic_incidence  pelvic_tilt numeric  lumbar_lordosis_angle  sacral_slope  \\\n",
            "0         63.027817            22.552586              39.609117     40.475232   \n",
            "1         39.056951            10.060991              25.015378     28.995960   \n",
            "2         68.832021            22.218482              50.092194     46.613539   \n",
            "3         69.297008            24.652878              44.311238     44.644130   \n",
            "4         49.712859             9.652075              28.317406     40.060784   \n",
            "\n",
            "   pelvic_radius  degree_spondylolisthesis     class  \n",
            "0      98.672917                 -0.254400  Abnormal  \n",
            "1     114.405425                  4.564259  Abnormal  \n",
            "2     105.985135                 -3.530317  Abnormal  \n",
            "3     101.868495                 11.211523  Abnormal  \n",
            "4     108.168725                  7.918501  Abnormal  \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 310 entries, 0 to 309\n",
            "Data columns (total 7 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   pelvic_incidence          310 non-null    float64\n",
            " 1   pelvic_tilt numeric       310 non-null    float64\n",
            " 2   lumbar_lordosis_angle     310 non-null    float64\n",
            " 3   sacral_slope              310 non-null    float64\n",
            " 4   pelvic_radius             310 non-null    float64\n",
            " 5   degree_spondylolisthesis  310 non-null    float64\n",
            " 6   class                     310 non-null    object \n",
            "dtypes: float64(6), object(1)\n",
            "memory usage: 17.1+ KB\n",
            "None\n",
            "Index(['pelvic_incidence', 'pelvic_tilt numeric', 'lumbar_lordosis_angle',\n",
            "       'sacral_slope', 'pelvic_radius', 'degree_spondylolisthesis', 'class'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv(\"/content/column_2C_weka.csv\", delimiter=',')\n",
        "print(dataset.describe())\n",
        "print()\n",
        "print(dataset.head(5))\n",
        "print()\n",
        "print(dataset.info())\n",
        "\n",
        "column_names = dataset.columns\n",
        "\n",
        "print(column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.2\n",
        "\n",
        "Import the necessary libraries"
      ],
      "metadata": {
        "id": "0h3DnXhjHLcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For data creation and other tasks\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "## Mertics to evaluate the models\n",
        "from sklearn . metrics import accuracy_score # for Logistic Regression\n",
        "\n",
        "# For plotting the graphs\n",
        "import matplotlib . pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "# For spliting the data into 80:20 ratio\n",
        "from sklearn . model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "6tYeTKlZG5G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.3\n",
        "\n",
        "Initialize weights and bias as 0:"
      ],
      "metadata": {
        "id": "u0oj5eWvIKyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weightInitialization(num_features):\n",
        "    # w = np.full((num_features, 1), 2)\n",
        "    w = np.zeros((num_features, 1))\n",
        "    b = 0.0\n",
        "    return w, b\n",
        "\n",
        "num_features = dataset.shape[1]-1  # excluding the last column: which is the label (not a feature, rather a class)\n",
        "\n",
        "w, b = weightInitialization(num_features)   # Initialize weights and bias\n",
        "\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "cjw4OhyGISyq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26495a84-75d1-4fd3-f2c7-c062805e6e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.4\n",
        "\n",
        "Sigmoid Function:"
      ],
      "metadata": {
        "id": "__ODXAtYLcT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The sigmoid activation\n",
        "def sigmoid_activation(z):\n",
        "    y = 1 / (1 + np.exp(-z))\n",
        "    return y"
      ],
      "metadata": {
        "id": "eEd_z-ifLjTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.5\n",
        "\n",
        "Model Optimization Function:"
      ],
      "metadata": {
        "id": "tZjt1BFARDgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_optimize(w, b, X, Y):\n",
        "    # 1. Get the number of data points (number of samples)\n",
        "    m = X.shape[1]\n",
        "\n",
        "    z = np.dot(w.T, X) + b\n",
        "\n",
        "    # 2. Get the prediction (activation) by applying the sigmoid function\n",
        "    A = sigmoid_activation(z)\n",
        "\n",
        "    # 3. Calculate the cost (loss) using the cross-entropy loss for logistic regression\n",
        "    cost = -1/m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
        "\n",
        "    # 4. Calculate the gradients (derivatives) of the cost with respect to weights and bias\n",
        "    dw = 1/m * np.dot(X, (A - Y).T)\n",
        "    db = 1/m * np.sum(A - Y)\n",
        "\n",
        "    # Create a dictionary to store gradients and cost\n",
        "    grads = {\"dw\": dw, \"db\": db}\n",
        "\n",
        "    return grads, cost\n",
        "\n",
        "\n",
        "# # Call the model_optimize function\n",
        "# grads, cost = model_optimize(w, b, X, y)\n",
        "\n",
        "# # Print the results\n",
        "# print(\"Gradients (dw):\", grads[\"dw\"])\n",
        "# print(\"Gradient (db):\", grads[\"db\"])\n",
        "# print(\"Cost:\", cost)\n"
      ],
      "metadata": {
        "id": "AQWL4QQ-N6fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.6\n",
        "\n",
        "Model Optimization: Run the optimization function for a given number of epochs and get the final weights along with a list of cost for each epoch"
      ],
      "metadata": {
        "id": "WprrkdVOWWxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_fit(w, b, X, Y, learning_rate, no_iterations):\n",
        "    costs = []\n",
        "    for i in range(no_iterations):\n",
        "        grads, cost = model_optimize(w, b, X, Y)\n",
        "        dw = grads[\"dw\"]\n",
        "        db = grads[\"db\"]\n",
        "\n",
        "        # Update the weights using gradient descent\n",
        "        w = w - learning_rate * dw\n",
        "        b = b - learning_rate * db\n",
        "\n",
        "        if (i % 10 == 0):\n",
        "            costs.append(cost)\n",
        "            # Print the cost if needed: print(\"Cost after %i iteration is %f\" % (i, cost))\n",
        "\n",
        "    # Final parameters (weights and bias)\n",
        "    coeff = {\"w\": w, \"b\": b}\n",
        "    return coeff, costs\n",
        "\n",
        "# # Define initial values\n",
        "# learning_rate = 0.01\n",
        "# no_iterations = 100\n",
        "\n",
        "# # Call the model_fit function\n",
        "# coeff, costs = model_fit(w, b, X_T, y, learning_rate, no_iterations)\n",
        "\n",
        "# # Print the final weights and bias\n",
        "# print(\"Final Weights (w):\", coeff[\"w\"])\n",
        "# print(\"Final Bias (b):\", coeff[\"b\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "GhrzKOZEWfaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.7\n",
        "\n",
        "Use logistic regression for the dataset"
      ],
      "metadata": {
        "id": "_6715gvdYBz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features (X) and labels (y)\n",
        "X = dataset.iloc[:, :-1]  # Select all columns except the last one as features\n",
        "y = dataset.iloc[:, -1].map({\"Normal\": 0, \"Abnormal\": 1})  # Select the last column as the label\n",
        "\n",
        "# Convert X and Y to a NumPy array\n",
        "X = X.values\n",
        "y = y.values\n",
        "\n",
        "# Normalize\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Step 1: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "y_train = y_train.reshape(1, -1)\n",
        "y_test = y_test.reshape(1, -1)\n",
        "\n",
        "# Step 2: Model Training\n",
        "num_features = X_train.shape[1]  # Number of features\n",
        "w, b = weightInitialization(num_features)  # Initialize weights and bias\n",
        "learning_rate = 0.01  # Set your learning rate\n",
        "no_iterations = 1000  # Set the number of iterations\n",
        "\n",
        "coeff, costs = model_fit(w, b, X_train.T, y_train, learning_rate, no_iterations)\n",
        "\n",
        "# Step 3: Get Predictions for the test dataset\n",
        "w_optimized = coeff[\"w\"]\n",
        "b_optimized = coeff[\"b\"]\n",
        "\n",
        "# Predict using the optimized weights and bias\n",
        "z = np.dot(w_optimized.T, X_test.T) + b_optimized        # computing z\n",
        "final_test_pred = sigmoid_activation(z)     # Use the computed 'z' values\n",
        "\n",
        "final_test_pred = (final_test_pred > 0.5).astype(int)\n",
        "\n",
        "# Step 4: Calculate Accuracy\n",
        "accuracy = accuracy_score(y_test.T, final_test_pred.T)\n",
        "print(\"Test Accuracy:\", accuracy * 100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7qhxUsQYJx_",
        "outputId": "f656ac47-a639-455a-ca60-20da279c6e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 74.19354838709677 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.8\n",
        "Plot the cost for each epoch: Use the costs list to plot the cost vs. epoch curve."
      ],
      "metadata": {
        "id": "BC8eThZcqoxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of epoch numbers\n",
        "epochs = list(range(0, len(costs) * 10, 10))\n",
        "\n",
        "# Plot the cost vs. epoch curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, costs, marker='o', linestyle='-')\n",
        "plt.title('Cost vs. Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uHgaKbdjyvgo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "52436da0-a863-4960-a4c8-ba523164fd96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.9\n",
        "Use smaller portion of training data: Show how the accuracy of the test dataset changes when you use 10%, 20%, and so on of the training dataset."
      ],
      "metadata": {
        "id": "q1aXan9IvBqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Split the data into training and testing sets\n",
        "for test_size in range(1, 100):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size/100, random_state=42)\n",
        "    y_train = y_train.reshape(1, -1)\n",
        "    y_test = y_test.reshape(1, -1)\n",
        "\n",
        "    # Step 2: Model Training\n",
        "    num_features = X_train.shape[1]  # Number of features\n",
        "    w, b = weightInitialization(num_features)  # Initialize weights and bias\n",
        "    learning_rate = 0.01  # Set your learning rate\n",
        "    no_iterations = 1000  # Set the number of iterations\n",
        "\n",
        "    coeff, costs = model_fit(w, b, X_train.T, y_train, learning_rate, no_iterations)\n",
        "\n",
        "    # Step 3: Get Predictions for the test dataset\n",
        "    w_optimized = coeff[\"w\"]\n",
        "    b_optimized = coeff[\"b\"]\n",
        "\n",
        "    # Predict using the optimized weights and bias\n",
        "    z = np.dot(w_optimized.T, X_test.T) + b_optimized        # computing z\n",
        "    final_test_pred = sigmoid_activation(z)     # Use the computed 'z' values\n",
        "\n",
        "    final_test_pred = (final_test_pred > 0.5).astype(int)\n",
        "\n",
        "    # Step 4: Calculate Accuracy\n",
        "    accuracy = accuracy_score(y_test.T, final_test_pred.T)\n",
        "\n",
        "    # Print the accuracy score for the current test_size\n",
        "    print(f\"Test Accuracy for test_size={test_size}%: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqSzq8hjvKer",
        "outputId": "02b2eb23-e9b0-4191-af48-a8d0364a88e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for test_size=1%: 75.00%\n",
            "Test Accuracy for test_size=2%: 85.71%\n",
            "Test Accuracy for test_size=3%: 80.00%\n",
            "Test Accuracy for test_size=4%: 76.92%\n",
            "Test Accuracy for test_size=5%: 62.50%\n",
            "Test Accuracy for test_size=6%: 68.42%\n",
            "Test Accuracy for test_size=7%: 72.73%\n",
            "Test Accuracy for test_size=8%: 76.00%\n",
            "Test Accuracy for test_size=9%: 78.57%\n",
            "Test Accuracy for test_size=10%: 74.19%\n",
            "Test Accuracy for test_size=11%: 74.29%\n",
            "Test Accuracy for test_size=12%: 76.32%\n",
            "Test Accuracy for test_size=13%: 78.05%\n",
            "Test Accuracy for test_size=14%: 77.27%\n",
            "Test Accuracy for test_size=15%: 74.47%\n",
            "Test Accuracy for test_size=16%: 74.00%\n",
            "Test Accuracy for test_size=17%: 73.58%\n",
            "Test Accuracy for test_size=18%: 73.21%\n",
            "Test Accuracy for test_size=19%: 72.88%\n",
            "Test Accuracy for test_size=20%: 70.97%\n",
            "Test Accuracy for test_size=21%: 69.70%\n",
            "Test Accuracy for test_size=22%: 71.01%\n",
            "Test Accuracy for test_size=23%: 72.22%\n",
            "Test Accuracy for test_size=24%: 73.33%\n",
            "Test Accuracy for test_size=25%: 73.08%\n",
            "Test Accuracy for test_size=26%: 72.84%\n",
            "Test Accuracy for test_size=27%: 73.81%\n",
            "Test Accuracy for test_size=28%: 73.56%\n",
            "Test Accuracy for test_size=29%: 73.33%\n",
            "Test Accuracy for test_size=30%: 74.19%\n",
            "Test Accuracy for test_size=31%: 73.20%\n",
            "Test Accuracy for test_size=32%: 72.00%\n",
            "Test Accuracy for test_size=33%: 71.84%\n",
            "Test Accuracy for test_size=34%: 72.64%\n",
            "Test Accuracy for test_size=35%: 72.48%\n",
            "Test Accuracy for test_size=36%: 73.21%\n",
            "Test Accuracy for test_size=37%: 73.04%\n",
            "Test Accuracy for test_size=38%: 72.88%\n",
            "Test Accuracy for test_size=39%: 73.55%\n",
            "Test Accuracy for test_size=40%: 73.39%\n",
            "Test Accuracy for test_size=41%: 72.66%\n",
            "Test Accuracy for test_size=42%: 72.52%\n",
            "Test Accuracy for test_size=43%: 71.64%\n",
            "Test Accuracy for test_size=44%: 71.53%\n",
            "Test Accuracy for test_size=45%: 72.14%\n",
            "Test Accuracy for test_size=46%: 71.33%\n",
            "Test Accuracy for test_size=47%: 70.55%\n",
            "Test Accuracy for test_size=48%: 71.14%\n",
            "Test Accuracy for test_size=49%: 71.05%\n",
            "Test Accuracy for test_size=50%: 70.97%\n",
            "Test Accuracy for test_size=51%: 71.07%\n",
            "Test Accuracy for test_size=52%: 70.99%\n",
            "Test Accuracy for test_size=53%: 70.30%\n",
            "Test Accuracy for test_size=54%: 70.24%\n",
            "Test Accuracy for test_size=55%: 70.76%\n",
            "Test Accuracy for test_size=56%: 71.26%\n",
            "Test Accuracy for test_size=57%: 71.19%\n",
            "Test Accuracy for test_size=58%: 71.11%\n",
            "Test Accuracy for test_size=59%: 71.04%\n",
            "Test Accuracy for test_size=60%: 70.97%\n",
            "Test Accuracy for test_size=61%: 70.53%\n",
            "Test Accuracy for test_size=62%: 69.95%\n",
            "Test Accuracy for test_size=63%: 69.90%\n",
            "Test Accuracy for test_size=64%: 70.35%\n",
            "Test Accuracy for test_size=65%: 70.79%\n",
            "Test Accuracy for test_size=66%: 69.76%\n",
            "Test Accuracy for test_size=67%: 69.71%\n",
            "Test Accuracy for test_size=68%: 69.19%\n",
            "Test Accuracy for test_size=69%: 69.63%\n",
            "Test Accuracy for test_size=70%: 69.12%\n",
            "Test Accuracy for test_size=71%: 68.78%\n",
            "Test Accuracy for test_size=72%: 68.75%\n",
            "Test Accuracy for test_size=73%: 68.72%\n",
            "Test Accuracy for test_size=74%: 68.70%\n",
            "Test Accuracy for test_size=75%: 69.10%\n",
            "Test Accuracy for test_size=76%: 68.64%\n",
            "Test Accuracy for test_size=77%: 68.62%\n",
            "Test Accuracy for test_size=78%: 68.60%\n",
            "Test Accuracy for test_size=79%: 68.16%\n",
            "Test Accuracy for test_size=80%: 67.74%\n",
            "Test Accuracy for test_size=81%: 67.86%\n",
            "Test Accuracy for test_size=82%: 67.45%\n",
            "Test Accuracy for test_size=83%: 67.44%\n",
            "Test Accuracy for test_size=84%: 67.82%\n",
            "Test Accuracy for test_size=85%: 68.18%\n",
            "Test Accuracy for test_size=86%: 68.16%\n",
            "Test Accuracy for test_size=87%: 68.15%\n",
            "Test Accuracy for test_size=88%: 68.13%\n",
            "Test Accuracy for test_size=89%: 67.75%\n",
            "Test Accuracy for test_size=90%: 67.38%\n",
            "Test Accuracy for test_size=91%: 67.84%\n",
            "Test Accuracy for test_size=92%: 67.83%\n",
            "Test Accuracy for test_size=93%: 67.82%\n",
            "Test Accuracy for test_size=94%: 67.81%\n",
            "Test Accuracy for test_size=95%: 67.46%\n",
            "Test Accuracy for test_size=96%: 67.45%\n",
            "Test Accuracy for test_size=97%: 67.77%\n",
            "Test Accuracy for test_size=98%: 67.43%\n",
            "Test Accuracy for test_size=99%: 67.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.10\n",
        "L1 L2 Regularization: Adapt the function model_optimize to include regularization."
      ],
      "metadata": {
        "id": "d0CB5a8hviiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_optimize_with_regularization(w, b, X, Y, reg=None, lambda_reg=0.1):\n",
        "    # 1. Get the number of data points (number of samples)\n",
        "    m = X.shape[1]\n",
        "\n",
        "    z = np.dot(w.T, X) + b        # computing z\n",
        "\n",
        "    # 2. Get the prediction (activation) by applying the sigmoid function\n",
        "    A = sigmoid_activation(z)\n",
        "\n",
        "    # 3. Calculate the cost (loss) depending on the regularization type (reg)\n",
        "    if reg == \"L1\":\n",
        "        cost = -1/m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A)) + lambda_reg/(2*m) * np.sum(np.abs(w))\n",
        "    elif reg == \"L2\":\n",
        "        cost = -1/m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A)) + lambda_reg/(2*m) * np.sum(w**2)\n",
        "    else:\n",
        "        cost = -(1/m) * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
        "\n",
        "    # 4. Calculate the gradients (derivatives) of the cost with respect to weights and bias\n",
        "    dw = 1/m * np.dot(X, (A - Y).T)\n",
        "    db = 1/m * np.sum(A - Y)\n",
        "\n",
        "    # Apply regularization to gradients if necessary\n",
        "    if reg == \"L1\":\n",
        "        dw += (lambda_reg / m) * np.sign(w)\n",
        "    elif reg == \"L2\":\n",
        "        dw += (lambda_reg / m) * w\n",
        "\n",
        "    # Create a dictionary to store gradients and cost\n",
        "    grads = {\"dw\": dw, \"db\": db}\n",
        "\n",
        "    return grads, cost\n"
      ],
      "metadata": {
        "id": "XgiIGr5xvjCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.11\n",
        "Accuracy change with regularization :\n",
        "\n",
        "Train the model for different epochs, different regularization (none, L1, L2) and different regularization coefficient values then show the test accuracies found in a table."
      ],
      "metadata": {
        "id": "QP61I1XUwG9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_fit_with_regularization(w, b, X, Y, reg, lambda_reg, no_iterations):\n",
        "    costs = []\n",
        "\n",
        "    for i in range(no_iterations):\n",
        "        grads, cost = model_optimize_with_regularization(w, b, X, Y, reg, lambda_reg)\n",
        "        dw = grads[\"dw\"]\n",
        "        db = grads[\"db\"]\n",
        "\n",
        "        w = w - learning_rate * dw\n",
        "        b = b - learning_rate * db\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            costs.append(cost)\n",
        "\n",
        "    coeff = {\"w\": w, \"b\": b}\n",
        "\n",
        "    return coeff, costs\n",
        "\n",
        "# Define a range of regularization coefficient values\n",
        "lambda_values = [0.001, 0.01, 0.1, 1.0]\n",
        "\n",
        "# Define a range of iteration values\n",
        "iteration_values = [100, 500, 1000, 2000]\n",
        "\n",
        "# Create an empty list to store results DataFrames\n",
        "results_dataframes = []\n",
        "\n",
        "# Loop through regularization types, lambda values, and iteration values\n",
        "for reg_type in [\"None\", \"L1\", \"L2\"]:\n",
        "    for lambda_reg in lambda_values:\n",
        "        for no_iterations in iteration_values:\n",
        "            # Initialize weights and bias\n",
        "            num_features = X_train.shape[1]\n",
        "            w, b = weightInitialization(num_features)\n",
        "\n",
        "            # Train the model with regularization\n",
        "            if reg_type == \"None\":\n",
        "                reg_type_display = \"No Regularization\"\n",
        "            elif reg_type == \"L1\":\n",
        "                reg_type_display = \"L1 Regularization\"\n",
        "            else:\n",
        "                reg_type_display = \"L2 Regularization\"\n",
        "\n",
        "            # Train the model with the current regularization type, lambda value, and iterations\n",
        "            coeff, _ = model_fit_with_regularization(w, b, X_train.T, y_train, reg_type, lambda_reg, no_iterations)\n",
        "\n",
        "            # Get optimized weights and bias\n",
        "            w_optimized = coeff[\"w\"]\n",
        "            b_optimized = coeff[\"b\"]\n",
        "\n",
        "            # Calculate test predictions\n",
        "            z = np.dot(w_optimized.T, X_test.T) + b_optimized\n",
        "            final_test_pred = sigmoid_activation(z)\n",
        "            final_test_pred = (final_test_pred > 0.5).astype(int)\n",
        "\n",
        "            # Calculate test accuracy\n",
        "            test_accuracy = accuracy_score(y_test.T, final_test_pred.T)\n",
        "\n",
        "            # Create a DataFrame for the current result\n",
        "            result_df = pd.DataFrame({\n",
        "                \"Regularization Type\": [reg_type_display],\n",
        "                \"Lambda\": [lambda_reg],\n",
        "                \"Iterations\": [no_iterations],\n",
        "                \"Test Accuracy\": [test_accuracy]\n",
        "            })\n",
        "\n",
        "            # Append the DataFrame to the list of results DataFrames\n",
        "            results_dataframes.append(result_df)\n",
        "\n",
        "\n",
        "# Concatenate all result DataFrames into a single results table\n",
        "results_table = pd.concat(results_dataframes, ignore_index=True)\n",
        "\n",
        "# Display the results table\n",
        "print(results_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECKjgEZlwMuD",
        "outputId": "b79739e8-d6e3-43d3-a265-a09799f6d498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Regularization Type  Lambda  Iterations  Test Accuracy\n",
            "0    No Regularization   0.001         100       0.677524\n",
            "1    No Regularization   0.001         500       0.677524\n",
            "2    No Regularization   0.001        1000       0.677524\n",
            "3    No Regularization   0.001        2000       0.677524\n",
            "4    No Regularization   0.010         100       0.677524\n",
            "5    No Regularization   0.010         500       0.677524\n",
            "6    No Regularization   0.010        1000       0.677524\n",
            "7    No Regularization   0.010        2000       0.677524\n",
            "8    No Regularization   0.100         100       0.677524\n",
            "9    No Regularization   0.100         500       0.677524\n",
            "10   No Regularization   0.100        1000       0.677524\n",
            "11   No Regularization   0.100        2000       0.677524\n",
            "12   No Regularization   1.000         100       0.677524\n",
            "13   No Regularization   1.000         500       0.677524\n",
            "14   No Regularization   1.000        1000       0.677524\n",
            "15   No Regularization   1.000        2000       0.677524\n",
            "16   L1 Regularization   0.001         100       0.677524\n",
            "17   L1 Regularization   0.001         500       0.677524\n",
            "18   L1 Regularization   0.001        1000       0.677524\n",
            "19   L1 Regularization   0.001        2000       0.674267\n",
            "20   L1 Regularization   0.010         100       0.677524\n",
            "21   L1 Regularization   0.010         500       0.677524\n",
            "22   L1 Regularization   0.010        1000       0.677524\n",
            "23   L1 Regularization   0.010        2000       0.667752\n",
            "24   L1 Regularization   0.100         100       0.677524\n",
            "25   L1 Regularization   0.100         500       0.677524\n",
            "26   L1 Regularization   0.100        1000       0.677524\n",
            "27   L1 Regularization   0.100        2000       0.677524\n",
            "28   L1 Regularization   1.000         100       0.677524\n",
            "29   L1 Regularization   1.000         500       0.677524\n",
            "30   L1 Regularization   1.000        1000       0.677524\n",
            "31   L1 Regularization   1.000        2000       0.677524\n",
            "32   L2 Regularization   0.001         100       0.677524\n",
            "33   L2 Regularization   0.001         500       0.677524\n",
            "34   L2 Regularization   0.001        1000       0.677524\n",
            "35   L2 Regularization   0.001        2000       0.674267\n",
            "36   L2 Regularization   0.010         100       0.677524\n",
            "37   L2 Regularization   0.010         500       0.677524\n",
            "38   L2 Regularization   0.010        1000       0.677524\n",
            "39   L2 Regularization   0.010        2000       0.671010\n",
            "40   L2 Regularization   0.100         100       0.677524\n",
            "41   L2 Regularization   0.100         500       0.677524\n",
            "42   L2 Regularization   0.100        1000       0.677524\n",
            "43   L2 Regularization   0.100        2000       0.674267\n",
            "44   L2 Regularization   1.000         100       0.677524\n",
            "45   L2 Regularization   1.000         500       0.677524\n",
            "46   L2 Regularization   1.000        1000       0.677524\n",
            "47   L2 Regularization   1.000        2000       0.677524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.12\n",
        "\n",
        "Logistic Regression Class from sklearn library:\n",
        "\n",
        "Use the Logistic Regression model from the sklearn library and find the accuracy after training."
      ],
      "metadata": {
        "id": "7AW4iI1N1PvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "logistic_regression = LogisticRegression()\n",
        "\n",
        "# Train the Logistic Regression model on the training data\n",
        "logistic_regression.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = logistic_regression.predict(X_test)\n",
        "\n",
        "# Evaluate the Logistic Regression model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Logistic Regression Model Accuracy:\", accuracy * 100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7ad3VFD1WzG",
        "outputId": "2723c570-5cb5-46fe-cc89-e210d9691205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model Accuracy: 79.56989247311827 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.13\n",
        "\n",
        "Decision Trees from sklearn library:\n",
        "\n",
        "Use the Decision Tree model from the sklearn library and find the accuracy after training."
      ],
      "metadata": {
        "id": "Z9PnQzYS1mva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a Decision Tree model\n",
        "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "decision_tree_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = decision_tree_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Decision Tree Accuracy:\", accuracy * 100, \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBzfdYNH1ris",
        "outputId": "c6be211d-8012-4878-c960-4a7eeda960fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 80.64516129032258 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.14\n",
        "\n",
        "Naive Bayes from sklearn library:\n",
        "\n",
        "Use the Naive Bayes model from the sklearn library and find the accuracy after\n",
        "training."
      ],
      "metadata": {
        "id": "S7HNYz2I2WOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a Gaussian Naive Bayes model\n",
        "naive_bayes_model = GaussianNB()\n",
        "\n",
        "# Train the model on the training data\n",
        "naive_bayes_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = naive_bayes_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Naive Bayes Accuracy:\", accuracy * 100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaGiqI7m2cHo",
        "outputId": "68434cbf-2106-4b82-8f4f-6044b2a12d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 79.56989247311827 %\n"
          ]
        }
      ]
    }
  ]
}